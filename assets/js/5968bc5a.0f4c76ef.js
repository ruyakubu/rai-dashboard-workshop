"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[664],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>f});var o=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,o,n=function(e,t){if(null==e)return{};var r,o,n={},i=Object.keys(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var p=o.createContext({}),l=function(e){var t=o.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},c=function(e){var t=l(e.components);return o.createElement(p.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,p=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=l(r),m=n,f=u["".concat(p,".").concat(m)]||u[m]||d[m]||i;return r?o.createElement(f,a(a({ref:t},c),{},{components:r})):o.createElement(f,a({ref:t},c))}));function f(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,a=new Array(i);a[0]=m;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[u]="string"==typeof e?e:n,a[1]=s;for(var l=2;l<i;l++)a[l]=r[l];return o.createElement.apply(null,a)}return o.createElement.apply(null,r)}m.displayName="MDXCreateElement"},1077:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var o=r(7462),n=(r(7294),r(3905));const i={id:"pf-intro",title:"Prompt Flow Overview",sidebar_position:1,slug:"/prompt-flow-overview"},a=void 0,s={unversionedId:"azure-prompt-flow/pf-intro",id:"azure-prompt-flow/pf-intro",title:"Prompt Flow Overview",description:"Prompt engineering is a tedious process that involves a lot tasks and components.  Developments have next determine what the input or prompts are going to be and what the actions we want in return.  In order to achieve, there are a lot of parts.  For instance, the prompts are responses need to be tokenize.  Next, depending on that the action that will be the output, we need to identify where that information is coming from.  Is the information coming from an API, or an LLM model?  When data is returned, does it need preprocessing?  How is the best response identify?",source:"@site/docs/azure-prompt-flow/intro.md",sourceDirName:"azure-prompt-flow",slug:"/prompt-flow-overview",permalink:"/rai-dashboard-workshop/docs/prompt-flow-overview",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"pf-intro",title:"Prompt Flow Overview",sidebar_position:1,slug:"/prompt-flow-overview"},sidebar:"mySidebar",previous:{title:"Lab# 4: Analyze Image",permalink:"/rai-dashboard-workshop/docs/content-safety-analyze-image"},next:{title:"Exercise# 1: Build Workshop Environment",permalink:"/rai-dashboard-workshop/docs/build-workshop-enviroment"}},p={},l=[{value:"\ud83c\udfaf | Objectives:",id:"--objectives",level:2},{value:"\u2705 |Prerequisites:",id:"-prerequisites",level:2}],c={toc:l},u="wrapper";function d(e){let{components:t,...i}=e;return(0,n.kt)(u,(0,o.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"Prompt engineering is a tedious process that involves a lot tasks and components.  Developments have next determine what the input or prompts are going to be and what the actions we want in return.  In order to achieve, there are a lot of parts.  For instance, the prompts are responses need to be tokenize.  Next, depending on that the action that will be the output, we need to identify where that information is coming from.  Is the information coming from an API, or an LLM model?  When data is returned, does it need preprocessing?  How is the best response identify?"),(0,n.kt)("p",null,(0,n.kt)("img",{src:r(7369).Z,width:"2077",height:"502"})),(0,n.kt)("p",null,"That\u2019s where Azure Prompt Flow, is valuable if providing a user-friendly logical flow to structure the different tasks involves and their dependencies.  To understand how to utilize Prompt Flow to expedite process of using an LLM that takes input and generates.  We are going to use a dental clinic\u2019s virtual chat agent takes input from users and provides an answer.  Since using OpenAI or any other LLM model is not going to know specific information about our Contoso dental client, we are going to use data for our clinic."),(0,n.kt)("p",null,(0,n.kt)("img",{src:r(3479).Z,width:"806",height:"102"})),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Custom Data"),":"),(0,n.kt)("h2",{id:"--objectives"},"\ud83c\udfaf | Objectives:"),(0,n.kt)("p",null,"After the workshop, you will learn how to:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Create a chatbot that uses an LLM model to generate responses"),(0,n.kt)("li",{parentName:"ul"},"Convert your own data to a vector index"),(0,n.kt)("li",{parentName:"ul"},"Use the LLM tool to create prompts and the response"),(0,n.kt)("li",{parentName:"ul"},"Embed user input to search a vector index"),(0,n.kt)("li",{parentName:"ul"},"Use Prompt tool to construct rules how your LLM should response.")),(0,n.kt)("h2",{id:"-prerequisites"},"\u2705 |Prerequisites:"),(0,n.kt)("p",null,"To complete this workshop, you need the following:"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Login or Signup for a ",(0,n.kt)("a",{parentName:"li",href:"https://azure.microsoft.com/free/"},"Free Azure account")),(0,n.kt)("li",{parentName:"ol"},"GitHub account with access to GitHub Codespaces."),(0,n.kt)("li",{parentName:"ol"},"Install Python 3.8 or higher.")))}d.isMDXComponent=!0},3479:(e,t,r)=>{r.d(t,{Z:()=>o});const o=r.p+"assets/images/rag-pattern-1b2e83defdb1354c2068eb4f0a516f56.png"},7369:(e,t,r)=>{r.d(t,{Z:()=>o});const o=r.p+"assets/images/vector-token-embed-0756002b21b7c6e86c0758d40a6ff5aa.png"}}]);