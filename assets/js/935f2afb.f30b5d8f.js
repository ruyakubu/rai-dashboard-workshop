"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"mySidebar":[{"type":"link","label":"1. Introduction","href":"/rai-dashboard-workshop/docs/welcome","docId":"welcome"},{"type":"category","label":"2. Prerequisites","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"2.1 Azure RAI dashboard","href":"/rai-dashboard-workshop/docs/azure-prerequistes","docId":"prerequisites/azure-prerequistes"},{"type":"link","label":"2.2 Open-Source RAI dashboard","href":"/rai-dashboard-workshop/docs/opensource-prerequistes","docId":"prerequisites/local-prerequistes"}]},{"type":"category","label":"3. Lab 1\ufe0f\u20e3 -  Error Analysis","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Find model errors","href":"/rai-dashboard-workshop/docs/find-treemap-errors","docId":"lab1-error-analysis/error-analysis-tree"}]},{"type":"category","label":"4. Lab 2\ufe0f\u20e3 - Model Analysis","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Analyze dataset cohort","href":"/rai-dashboard-workshop/docs/analyze-dataset-cohort","docId":"lab2-model-overview/analyze-dataset-cohort"},{"type":"link","label":"Analyze feature cohorts","href":"/rai-dashboard-workshop/docs/analyze-feature-cohort","docId":"lab2-model-overview/analyze-feature-cohort"}]},{"type":"category","label":"5. Lab 3\ufe0f\u20e3 -  Data Analysis","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Data Analysis chart view","href":"/rai-dashboard-workshop/docs/data-analysis-chart-view","docId":"lab3-data-analysis/data-analysis-chart-view"}]},{"type":"category","label":"6. Lab 4\ufe0f\u20e3 - Feature Importance","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Global Feature Importance","href":"/rai-dashboard-workshop/docs/view-feature-importance","docId":"lab4-feature-importance/view- feature-importance"},{"type":"link","label":"Local Feature Importance","href":"/rai-dashboard-workshop/docs/view-individual-feature-importance","docId":"lab4-feature-importance/view-individual-feature-importance"}]},{"type":"link","label":"7. Shutdown","href":"/rai-dashboard-workshop/docs/stop-compute","docId":"shutdown-compute"},{"type":"link","label":"8. References","href":"/rai-dashboard-workshop/docs/references","docId":"References"},{"type":"link","label":"9. Survey","href":"/rai-dashboard-workshop/docs/survey","docId":"Survey"}]},"docs":{"lab1-error-analysis/error-analysis-tree":{"id":"lab1-error-analysis/error-analysis-tree","title":"Find model errors","description":"We rely on traditional model performance to give us the overall \\"accuracy\\" of a model.  However,  we fail to realize that there are areas in the data where the model performs very poorly.  The Error Analysis section of the RAI dashboard helps provide an error distribution of the feature groups contributing to the error rate of the model.  Errors are often not distributed evenly across different data subgroups and Error Analysis helps you identify features with the highest error rates.","sidebar":"mySidebar"},"lab2-model-overview/analyze-dataset-cohort":{"id":"lab2-model-overview/analyze-dataset-cohort","title":"Analyze dataset cohort","description":"Part of evaluating the performance of a machine learning model is getting a wholistic understanding of its behavior.  This sometimes involves doing comparative analysis helps shed light on how the model is performing with one subgroup of the dataset vs another.   In some case feature-based analysis is necessary to isolate the data and pinpoint the root cause of some of the errors.","sidebar":"mySidebar"},"lab2-model-overview/analyze-feature-cohort":{"id":"lab2-model-overview/analyze-feature-cohort","title":"Analyze feature cohorts","description":"The RAI dashboard helps data scientist or AI developers examine the model performance across different cohorts within a given feature as well. Whether it is one feature, or a combination of two features, the RAI dashboard has built-in intelligence to divided feature values into various meaningful cohorts for users to do feature-based analysis and compare where the model is not doing well.  Since the cohort with the highest error has patients with the number of Prior_Inpatient > 0 days, taking a closer look at the \u201cPrior_Inpatient\u201d will help isolate where there are issues.","sidebar":"mySidebar"},"lab3-data-analysis/data-analysis-chart-view":{"id":"lab3-data-analysis/data-analysis-chart-view","title":"Data Analysis chart view","description":"There are number of issues that could cause model inaccuracies.  For instance, data can be overrepresented in some cases or underrepresented in others. Not having a good balance of data can negatively skew a model\u2019s performance. This leads to data biases causing the model not to be fair, inclusive, safe, or reliable.  The Azure Responsible AI dashboard includes a Data Analysis section for users to be able to explore and understand the dataset distributions and statistics. It provides an interactive user interface (UI) to enable users to visualize datasets based on the predicted and actual outcomes, error groups, and specific features. As a result, the insights help ML professionals to better understand and pinpoint the root cause of errors.","sidebar":"mySidebar"},"lab4-feature-importance/view- feature-importance":{"id":"lab4-feature-importance/view- feature-importance","title":"Global Feature Importance","description":"Part of training a model is not just to see how accurate it can make a prediction, but why it made the prediction.   Understanding and explaining a model\u2019s behavior is part of ensuring it is fair, inclusive, reliable and accountable.  Some industries have compliance regulations that require organizations to provide an explanation for how and why a model made the prediction it did. The Azure Responsible AI (RAI) dashboard provides the Feature Importance section that is an interactive user interface (UI) which enables data scientists or AI developers to see top features in their dataset that drove a model\u2019s prediction.","sidebar":"mySidebar"},"lab4-feature-importance/view-individual-feature-importance":{"id":"lab4-feature-importance/view-individual-feature-importance","title":"Local Feature Importance","description":"The RAI dashboard Feature Importance section has a table view that enables users to see which records the model made a correct vs incorrect prediction.  You can use each individual patient\'s record to see which features positively or negatively drove that individual outcome. This is especially useful when debugging to see where the model is performing erroneously for a specific patient, and which features are positive or negative contributors.   In our case, you\'ll focus on the cohort with the highest errors.","sidebar":"mySidebar"},"prerequisites/azure-prerequistes":{"id":"prerequisites/azure-prerequistes","title":"2.1 Azure RAI dashboard","description":"Azure subscription account","sidebar":"mySidebar"},"prerequisites/local-prerequistes":{"id":"prerequisites/local-prerequistes","title":"2.2 Open-Source RAI dashboard","description":"Open-source Responsible AI Toolbox","sidebar":"mySidebar"},"References":{"id":"References","title":"8. References","description":"To get a deeper understanding of all the Responsible AI dashboard features and components, refer to the following tutorials series:","sidebar":"mySidebar"},"shutdown-compute":{"id":"shutdown-compute","title":"7. Shutdown","description":"Be sure to shutdown the compute instance at the end of this workshop so you do not run out of credits.","sidebar":"mySidebar"},"Survey":{"id":"Survey","title":"9. Survey","description":"Congratulations on completing the workshop! We hope you enjoyed the experience and learned a lot about the Responsible AI dashboard. We would love to hear your feedback on the training. Please take a few minutes to complete the survey below.","sidebar":"mySidebar"},"welcome":{"id":"welcome","title":"1. Introduction","description":"This workshop is for participants to get hands-on learning on how to use the Responsible AI dashboard to debug their machine learning model in order to improve the model\'s performance to be more fair, inclusive, safe & reliable, and transparent.  The workshop will cover how to use Error Analysis, Model Overview, Data Analysis and Feature Importance in end-to-end machine learning life cycles.  After completing this workshop, participant will learn best practices of using Azure Responsible AI dashboard to produce AI solution that are less harmful to society and more trustworthy.","sidebar":"mySidebar"}}}')}}]);